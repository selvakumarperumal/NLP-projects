{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a8f3dcbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-13 13:45:08.318273: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-12-13 13:45:08.318323: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2022-12-13 13:45:19.859345: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2022-12-13 13:45:19.859430: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-12-13 13:45:19.859502: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (u): /proc/driver/nvidia/version does not exist\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "65bb7d3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/train.txt') as f:\n",
    "    line = f.readline()\n",
    "    line2 = f.readline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d26cf936",
   "metadata": {},
   "outputs": [],
   "source": [
    "def txt2array(path):\n",
    "    txt, label = [], []\n",
    "    with open(path) as f:\n",
    "        while True:\n",
    "            line = f.readline()\n",
    "            if not line:\n",
    "                break\n",
    "            tmp = line.strip().split(';')\n",
    "            if len(tmp)>1:\n",
    "                txt.append(tmp[0])\n",
    "                label.append(tmp[1])\n",
    "            else:\n",
    "                txt.append(tmp[0])\n",
    "    if label:\n",
    "        return txt, label\n",
    "    else:\n",
    "        return txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47a9999a",
   "metadata": {},
   "source": [
    "### Converting Text file to Array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f0980e61",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_txt, train_label = txt2array('../data/train.txt')\n",
    "val_txt, val_label = txt2array('../data/val.txt')\n",
    "test_txt, test_label = txt2array('../data/test.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7299ff3",
   "metadata": {},
   "source": [
    "### Array to DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c9b575b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dict = {\"txt\":train_txt, \"label\":train_label}\n",
    "test_dict = {\"txt\":test_txt, \"label\":test_label}\n",
    "val_dict = {\"txt\":test_txt, \"label\":test_label}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "98f4c941",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.DataFrame(train_dict)\n",
    "test_df = pd.DataFrame(test_dict)\n",
    "val_df = pd.DataFrame(val_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1d13dbf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = train_df.label.unique()\n",
    "unique_emo = {}\n",
    "for i in range(len(tmp)):\n",
    "    unique_emo[tmp[i]] = i    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2ad6960d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['label_num'] = train_df['label'].map(unique_emo)\n",
    "test_df['label_num'] = test_df['label'].map(unique_emo)\n",
    "val_df['label_num'] = val_df['label'].map(unique_emo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ea7d43f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>txt</th>\n",
       "      <th>label</th>\n",
       "      <th>label_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i didnt feel humiliated</td>\n",
       "      <td>sadness</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i can go from feeling so hopeless to so damned...</td>\n",
       "      <td>sadness</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>im grabbing a minute to post i feel greedy wrong</td>\n",
       "      <td>anger</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i am ever feeling nostalgic about the fireplac...</td>\n",
       "      <td>love</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i am feeling grouchy</td>\n",
       "      <td>anger</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 txt    label  label_num\n",
       "0                            i didnt feel humiliated  sadness          0\n",
       "1  i can go from feeling so hopeless to so damned...  sadness          0\n",
       "2   im grabbing a minute to post i feel greedy wrong    anger          1\n",
       "3  i am ever feeling nostalgic about the fireplac...     love          2\n",
       "4                               i am feeling grouchy    anger          1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "282d1f1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = train_df['txt']\n",
    "y_train = train_df['label_num']\n",
    "\n",
    "x_test = test_df['txt']\n",
    "y_test = test_df['label_num']\n",
    "\n",
    "x_val = val_df['txt']\n",
    "y_val = val_df['label_num']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d089ce0c",
   "metadata": {},
   "source": [
    "## Without Pre-processing Text data\n",
    "### Random Forest\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4b6eb34d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.36      0.46       581\n",
      "           1       0.48      0.20      0.29       275\n",
      "           2       0.48      0.13      0.20       159\n",
      "           3       0.47      0.14      0.21        66\n",
      "           4       0.50      0.23      0.32       224\n",
      "           5       0.44      0.87      0.58       695\n",
      "\n",
      "    accuracy                           0.48      2000\n",
      "   macro avg       0.50      0.32      0.34      2000\n",
      "weighted avg       0.51      0.48      0.43      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = Pipeline([('Vec_3grams', CountVectorizer(ngram_range=(3, 3))), #with tri-grams\n",
    "               ('RF', RandomForestClassifier())])\n",
    "\n",
    "clf.fit(x_train, y_train)\n",
    "\n",
    "y_test_pred = clf.predict(x_test)\n",
    "\n",
    "print(classification_report(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e1db7bc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.91      0.92       581\n",
      "           1       0.92      0.83      0.87       275\n",
      "           2       0.84      0.58      0.68       159\n",
      "           3       0.75      0.55      0.63        66\n",
      "           4       0.90      0.79      0.84       224\n",
      "           5       0.80      0.96      0.88       695\n",
      "\n",
      "    accuracy                           0.86      2000\n",
      "   macro avg       0.86      0.77      0.80      2000\n",
      "weighted avg       0.87      0.86      0.86      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = Pipeline([('Vec_3grams', CountVectorizer(ngram_range=(1, 2))), #with 1-grams and bi-grams\n",
    "               ('RF', RandomForestClassifier())])\n",
    "\n",
    "clf.fit(x_train, y_train)\n",
    "\n",
    "y_test_pred = clf.predict(x_test)\n",
    "\n",
    "print(classification_report(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9a4a32fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.90      0.91       581\n",
      "           1       0.91      0.83      0.87       275\n",
      "           2       0.81      0.64      0.71       159\n",
      "           3       0.62      0.59      0.60        66\n",
      "           4       0.87      0.82      0.84       224\n",
      "           5       0.83      0.94      0.88       695\n",
      "\n",
      "    accuracy                           0.86      2000\n",
      "   macro avg       0.83      0.79      0.80      2000\n",
      "weighted avg       0.87      0.86      0.86      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = Pipeline([('TF-IDF', TfidfVectorizer()), #with TF-IDF\n",
    "               ('RF', RandomForestClassifier())])\n",
    "\n",
    "clf.fit(x_train, y_train)\n",
    "\n",
    "y_test_pred = clf.predict(x_test)\n",
    "\n",
    "print(classification_report(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "229d37d4",
   "metadata": {},
   "source": [
    "### Multinomial Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "85a40eee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.58      0.55       581\n",
      "           1       0.59      0.17      0.27       275\n",
      "           2       0.33      0.06      0.10       159\n",
      "           3       0.50      0.03      0.06        66\n",
      "           4       0.54      0.20      0.29       224\n",
      "           5       0.48      0.80      0.60       695\n",
      "\n",
      "    accuracy                           0.50      2000\n",
      "   macro avg       0.49      0.31      0.31      2000\n",
      "weighted avg       0.50      0.50      0.45      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = Pipeline([('Vec_3grams', CountVectorizer(ngram_range=(3, 3))), #with tri-grams\n",
    "               ('NB', MultinomialNB())])\n",
    "\n",
    "clf.fit(x_train, y_train)\n",
    "\n",
    "y_test_pred = clf.predict(x_test)\n",
    "\n",
    "print(classification_report(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a371e4b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.90      0.77       581\n",
      "           1       0.96      0.16      0.28       275\n",
      "           2       1.00      0.03      0.05       159\n",
      "           3       0.00      0.00      0.00        66\n",
      "           4       1.00      0.18      0.31       224\n",
      "           5       0.60      0.99      0.75       695\n",
      "\n",
      "    accuracy                           0.65      2000\n",
      "   macro avg       0.71      0.38      0.36      2000\n",
      "weighted avg       0.73      0.65      0.56      2000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/s/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/s/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "clf = Pipeline([('TF-IDF', TfidfVectorizer()), #with TF-IDF\n",
    "               ('NB', MultinomialNB())])\n",
    "\n",
    "clf.fit(x_train, y_train)\n",
    "\n",
    "y_test_pred = clf.predict(x_test)\n",
    "\n",
    "print(classification_report(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d26089b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_md')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0d314be1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Preprocess(txt):\n",
    "    doc = nlp(txt)\n",
    "    tmp = []\n",
    "    for token in doc:\n",
    "        if not token.is_stop or not token.is_punct:\n",
    "            tmp.append(token.lemma_)\n",
    "    return \" \".join(tmp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d3a4f28",
   "metadata": {},
   "source": [
    "### With Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "64241eca",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.apply(Preprocess)\n",
    "x_test = x_test.apply(Preprocess)\n",
    "x_val = x_val.apply(Preprocess)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4477ed7",
   "metadata": {},
   "source": [
    "### RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "14bcf3de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.87      0.89       581\n",
      "           1       0.89      0.77      0.83       275\n",
      "           2       0.81      0.57      0.67       159\n",
      "           3       0.68      0.55      0.61        66\n",
      "           4       0.85      0.84      0.85       224\n",
      "           5       0.80      0.94      0.86       695\n",
      "\n",
      "    accuracy                           0.84      2000\n",
      "   macro avg       0.82      0.76      0.78      2000\n",
      "weighted avg       0.85      0.84      0.84      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = Pipeline([('TF-IDF', TfidfVectorizer()), #with TF-IDF\n",
    "               ('RF', RandomForestClassifier())])\n",
    "\n",
    "clf.fit(x_train, y_train)\n",
    "\n",
    "y_test_pred = clf.predict(x_test)\n",
    "\n",
    "print(classification_report(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6f7b06c",
   "metadata": {},
   "source": [
    "### NB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "045b48fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.89      0.77       581\n",
      "           1       0.93      0.20      0.33       275\n",
      "           2       1.00      0.03      0.06       159\n",
      "           3       0.00      0.00      0.00        66\n",
      "           4       0.96      0.21      0.35       224\n",
      "           5       0.61      0.99      0.76       695\n",
      "\n",
      "    accuracy                           0.66      2000\n",
      "   macro avg       0.70      0.39      0.38      2000\n",
      "weighted avg       0.73      0.66      0.58      2000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/s/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/s/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "clf = Pipeline([('TF-IDF', TfidfVectorizer()), #with TF-IDF\n",
    "               ('NB', MultinomialNB())])\n",
    "\n",
    "clf.fit(x_train, y_train)\n",
    "\n",
    "y_test_pred = clf.predict(x_test)\n",
    "\n",
    "print(classification_report(y_test, y_test_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
